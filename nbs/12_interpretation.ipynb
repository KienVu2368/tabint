{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import sys\n",
    "path = '/home/ddpham/git/tabint/'\n",
    "sys.path.insert(1, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'tabint.learner' has no attribute 'BaseLeaner' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d668ec325f9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtabint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtabint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtabint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearSegmentedColormap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtabint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/tabint/tabint/learner.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvisual\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/tabint/tabint/visual.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpre_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'tabint.learner' has no attribute 'BaseLeaner' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import pdpbox\n",
    "from pdpbox import pdp, info_plots\n",
    "from tabint.utils import *\n",
    "from tabint.pre_processing import *\n",
    "from tabint.learner import *\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from tabint.dataset import *\n",
    "import graphviz\n",
    "import shap\n",
    "import shap.plots.colors as cl\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PartialDependence:\n",
    "    \"\"\"\n",
    "    Partial dependence https://github.com/SauceCat/PDPbox\n",
    "    \"\"\"\n",
    "    def __init__(self, md, df, features, target):\n",
    "        self.md = md\n",
    "        self.df = df\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.summary = {}\n",
    "        \n",
    "    @classmethod    \n",
    "    def from_Learner(cls, learner, ds):\n",
    "        df = ds.x_trn.copy()\n",
    "        features = df.columns\n",
    "        \n",
    "        if len(ds.y_trn.shape) == 1:\n",
    "            df['target'] = ds.y_trn\n",
    "            target = ['target']\n",
    "        else:\n",
    "            target = []\n",
    "            for i in range(ds.y_trn.shape.shape[1]):\n",
    "                tgt_name = 'target' + str(i)\n",
    "                df[tgt_name] = ds.y_trn.iloc[:,i]\n",
    "                target.append(tgt_name)\n",
    "        return cls(learner.md, df, features, target)\n",
    "    \n",
    "    def info_target_plot(self, feature, sample = 10000, target = None, grid_type = 'percentile', **kargs):\n",
    "        fig, axes, result = info_plots.target_plot(\n",
    "                df=self.sample(sample), feature=feature, feature_name=feature, \n",
    "                target=target or self.target, grid_type = grid_type, **kargs)\n",
    "        self.info_target_data =  ResultDF(result, 'count')\n",
    "\n",
    "        _ = axes['bar_ax'].set_xticklabels(self.summary['info_target'].display_column.values)\n",
    "        plt.show()    \n",
    "    \n",
    "    def info_actual_plot(self, feature, sample = 10000, predict_kwds = {}, which_classes=None, **kargs):\n",
    "        fig, axes, result = info_plots.actual_plot(\n",
    "                model=self.md, \n",
    "                X=self.sample(sample), \n",
    "                feature=feature, feature_name=feature,\n",
    "                predict_kwds=predict_kwds, which_classes = which_classes, **kargs)\n",
    "        self.info_actual_data =  ResultDF(result, 'count')\n",
    "        plt.show()        \n",
    "    \n",
    "    def isolate_plot(self, feature, sample = 10000,\n",
    "                num_grid_points=10, grid_type='percentile',\n",
    "                center = True, plot_lines=True, frac_to_plot=100, plot_pts_dist=True, \n",
    "                cluster=True, n_cluster_centers=10, cluster_method='accurate',\n",
    "                which_classes= None, **pdp_kargs):\n",
    "        ft_plot = pdp.pdp_isolate(\n",
    "                model=self.md, dataset=self.sample(sample), \n",
    "                model_features = self.features, feature=feature,\n",
    "                num_grid_points=num_grid_points, grid_type=grid_type,\n",
    "                n_jobs=-1, **pdp_kargs)\n",
    "\n",
    "        fig, axes = pdp.pdp_plot(\n",
    "                pdp_isolate_out=ft_plot, feature_name=feature,\n",
    "                center=center, plot_lines=plot_lines, frac_to_plot=frac_to_plot, plot_pts_dist=plot_pts_dist, \n",
    "                cluster=cluster, n_cluster_centers=n_cluster_centers, which_classes=which_classes)\n",
    "        plt.show()\n",
    "        \n",
    "    def target_interact_plot(self, feature, var_name = None, target=None, sample = 10000, show_outliers=True, **kargs):\n",
    "        fig, axes, self.summary['target_interact'] = info_plots.target_plot_interact(\n",
    "                df=self.sample(sample), target= target or self.target,\n",
    "                features= feature, feature_names = var_name or feature,\n",
    "                show_outliers=show_outliers, **kargs)\n",
    "        plt.show()\n",
    "        \n",
    "    def actual_interact_plot(self, feature, var_name = None, sample = 10000, which_classes = None, show_outliers=True, **kargs):\n",
    "        fig, axes, result = info_plots.actual_plot_interact(\n",
    "                model = self.md, X = self.sample(sample),\n",
    "                features=feature, feature_names=var_name or feature, \n",
    "                which_classes=which_classes, show_outliers= show_outliers, **kargs)\n",
    "        self.actual_interact_data =  ResultDF(result, 'count')\n",
    "        plt.show()\n",
    "        \n",
    "    def pdp_interact_plot(self, feature, var_name=None, sample = 10000, which_classes = None,\n",
    "                     num_grid_points=[10, 10], plot_types = None, plot_params = {'cmap': [\"#00cc00\", \"#002266\"]}):        \n",
    "        ft_plot = pdp.pdp_interact(\n",
    "                model=self.md, dataset=self.sample(sample), \n",
    "                model_features=self.features, features=feature, \n",
    "                num_grid_points=num_grid_points, n_jobs=4)\n",
    "        \n",
    "        plot_types = ['contour', 'grid'] if plot_types is None else [plot_types]\n",
    "        for plot_type in plot_types:\n",
    "            figs, ax = pdp.pdp_interact_plot(\n",
    "                pdp_interact_out = ft_plot, \n",
    "                feature_names = var_name or feature, \n",
    "                plot_type= plot_type, plot_pdp=True, \n",
    "                which_classes=which_classes, plot_params = plot_params)\n",
    "        plt.show()\n",
    "    \n",
    "    def sample(self, sample): return self.df if sample is None else self.df.sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearSegmentedColormap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bcf43d41498f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#harcode to change shap color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgreen_blue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSegmentedColormap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'custom blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'#ffff00'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'#002266'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mred_blue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgreen_blue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mred_blue_solid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgreen_blue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LinearSegmentedColormap' is not defined"
     ]
    }
   ],
   "source": [
    "#export\n",
    "#harcode to change shap color\n",
    "green_blue = LinearSegmentedColormap.from_list('custom blue', [(0, '#ffff00'), (1, '#002266')], N=256)\n",
    "cl.red_blue = green_blue\n",
    "cl.red_blue_solid = green_blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Shapley:\n",
    "    \"\"\"\n",
    "    SHAP value: https://github.com/slundberg/shap\n",
    "    \"\"\"\n",
    "    def __init__(self, explainer, shap_values, df, df_disp, features):\n",
    "        shap.initjs()\n",
    "        self.explainer = explainer\n",
    "        self.shap_values = shap_values\n",
    "        self.df, self.df_disp, self.features = df, df_disp, features        \n",
    "    \n",
    "    @classmethod\n",
    "    def from_Tree(cls, learner, ds, df_disp = None, sample = 10000, remove_outlier = True):\n",
    "\n",
    "        if remove_outlier: \n",
    "            df, _, mask = ds.remove_outlier(inplace = False, return_mask = True)\n",
    "            #if df_disp is not None: df_disp = df_disp.copy(); df_disp = df_disp[mask]\n",
    "        else:\n",
    "            df = ds.x_trn\n",
    "\n",
    "        if sample < df.shape[0]:\n",
    "            samp = np.random.choice(df.shape[0], sample)\n",
    "            df = df.iloc[samp]\n",
    "            if df_disp is not None: df_disp = df_disp.iloc[samp]\n",
    "        \n",
    "        for c, v in df.items(): \n",
    "            if v.dtypes.name[:3] == 'int': df[c] = df[c].astype(np.float32)\n",
    "        \n",
    "        explainer = shap.TreeExplainer(learner.md)\n",
    "        shap_values = explainer.shap_values(df)\n",
    "        features = df.columns\n",
    "        return cls(explainer, shap_values, df, df_disp, features)\n",
    "\n",
    "    @classmethod\n",
    "    def from_kernel(cls): None\n",
    "\n",
    "    def one_force_plot(self, loc = None, record = None, link='identity', plot_cmap = [\"#00cc00\", \"#002266\"]):\n",
    "        s_values = self.shap_values[loc] if loc is not None else self.explainer.shap_values(record)[0]\n",
    "        col_value = self.df.iloc[[loc]].values if loc is not None else record.values\n",
    "        result = pd.DataFrame({'feature': self.features, 'feature value': col_value[0], 'Shap value': s_values})\n",
    "        self.one_force_data = ResultDF(result, 'Shap value')\n",
    "        return shap.force_plot(self.explainer.expected_value, s_values, features = self.features, plot_cmap = plot_cmap, link = link)\n",
    "    \n",
    "    def many_force_plot(self, loc, sample = 10000, plot_cmap = [\"#00cc00\", \"#002266\"]):\n",
    "        return shap.force_plot(self.explainer.expected_value, self.shap_values[:loc,:], features = self.features, plot_cmap = plot_cmap)\n",
    "    \n",
    "    def summary_plot(self, plot_type = 'violin', alpha=0.3):\n",
    "        \"\"\"violin, layered_violin, dot\"\"\"\n",
    "        return shap.summary_plot(self.shap_values, self.df, alpha=alpha, plot_type = plot_type)\n",
    "\n",
    "    def importance_plot(self):\n",
    "        return shap.summary_plot(self.shap_values, self.df, plot_type=\"bar\")\n",
    "        \n",
    "    def interaction_plot(self, sample = 100):\n",
    "        self.interaction_values = self.explainer.shap_interaction_values(self.df.sample(sample))\n",
    "        return shap.summary_plot(self.interaction_values, features = self.features)\n",
    "    \n",
    "    def dependence_plot(self, col1, col2 = 'auto', alpha = 0.3, x_jitter = 0.5, dot_size=50, df_disp= None):\n",
    "        return shap.dependence_plot(ind = col1, interaction_index = col2, \n",
    "                                    shap_values = self.shap_values, features = self.df, display_features = self.df_disp or df_disp,\n",
    "                                    alpha = alpha, dot_size=dot_size, x_jitter = x_jitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Shapley_approx:\n",
    "    \"\"\"https://link.springer.com/article/10.1007/s10115-013-0679-x\"\"\"\n",
    "    def __init__(self, shap_values, features, data):\n",
    "        self.features = features\n",
    "        self.shap_values =  shap_values\n",
    "        self.data = data\n",
    "\n",
    "    @classmethod\n",
    "    def from_ds(cls, ds):\n",
    "        #wip\n",
    "        features = ds.features\n",
    "        return cls(features)\n",
    "\n",
    "    @classmethod\n",
    "    def from_sequence(cls, learner, seq_df, instance, n_sample, features):\n",
    "        df_sample = numpy_sample(seq_df, n_sample, 1)\n",
    "        features_permute = np.array([np.random.permutation(i) for i in np.tile(np.array(list(range(len(features)))),(n_sample,1))])\n",
    "        shap_values = cal_shap(learner, df_sample, instance, features, features_permute, n_sample)\n",
    "        data = pd.DataFrame({'feature': features, 'shap_values': shap_values})\n",
    "        return cls(shap_values, features, ResultDF(data, 'shap_values'))\n",
    "\n",
    "    def construct_seq_instances(self, df_sample, instance, ith, features_permute):\n",
    "        b1 = [np.concatenate([instance[:,:,:ith+1],df_sample[:,j:j+1,fts[ith+1:]]],axis=2) for j, fts in enumerate(features_permute)]\n",
    "        b1 = np.concatenate(b1,axis=1)\n",
    "\n",
    "        b2 = [np.concatenate([instance[:,:,:ith],df_sample[:,j:j+1,fts[ith:]]],axis=2) for j, fts in enumerate(features_permute)]\n",
    "        b2 = np.concatenate(b2,axis=1)\n",
    "        return b1, b2\n",
    "\n",
    "    def cal_shap(self, learner, df_sample, instance, features, features_permute, n_sample):\n",
    "        shap_values = []\n",
    "        #to do nested for loop\n",
    "        for i,f in enumerate(features):\n",
    "            b1, b2 = construct_seq_instances(df_sample, instance, i, features_permute)\n",
    "            phi = np.sum(learner.predict(b1) - learner.predict(b2))/n_sample\n",
    "            shap_values.append(phi)\n",
    "        return shap_values\n",
    "\n",
    "    def plot(self, absolute=True, **kargs):\n",
    "        plot_barh_from_series(self.features, self.shap_values, absolute=absolute, **kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Traterfall:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    @classmethod\n",
    "    def from_df_loc(cls, learner, df, loc):\n",
    "        return cls.from_record(learner, df.iloc[[loc]])\n",
    "\n",
    "    @classmethod\n",
    "    def from_record(cls, learner, record):\n",
    "        prediction, bias, contributions = ti.predict(learner.md, record)\n",
    "        contributions = [contributions[0][i][0] for i in range(len(contributions[0]))]\n",
    "        data = pd.DataFrame({'feature': df.columns, 'value': record.values, 'contribute': contributions})\n",
    "        return cls(ResultDF(data, 'contribute'))\n",
    "        \n",
    "    def plot(self, rotation_value=90, threshold=0.2, sorted_value=True, **kargs):\n",
    "        my_plot = plot_waterfall(self.data().feature, self.data().contribute, rotation_value, threshold, sorted_value,**kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DrawTree:\n",
    "    def __init__(self, es, features, tp):\n",
    "        self.es = es\n",
    "        self.features = features\n",
    "        self.tp = tp\n",
    "        \n",
    "    @classmethod\n",
    "    def from_SKLearn(cls, learner, ds, num_estimator = 0, size=10, ratio=0.6, precision=0):\n",
    "        return cls(learner.md.estimators_, ds.features, 'SKTree')\n",
    "    \n",
    "    @classmethod\n",
    "    def from_LGB(cls, learner): return cls(learner.md, None, 'LGB')\n",
    "    \n",
    "    @classmethod\n",
    "    def from_XGB(cls): return None\n",
    "    \n",
    "    def plot(self, num_estimator = 0, **kargs): \n",
    "        if self.tp == 'SKTree': plot_SKTree(self.es[num_estimator], self.features, **kargs)\n",
    "        elif self.tp =='LGB': plot_LGBTree(self.es, num_estimator, **kargs)\n",
    "        elif self.tp == 'XGB': None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 12_interpretation.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script('12_interpretation.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
